{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "import pickle as pickle\n",
    "import tabulate\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>num movies</th>\n",
       "      <th>ave rating/genre</th>\n",
       "      <th>ratings per genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>321</td>\n",
       "      <td>3.37</td>\n",
       "      <td>10377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>234</td>\n",
       "      <td>3.42</td>\n",
       "      <td>8785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animation</td>\n",
       "      <td>76</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children</td>\n",
       "      <td>69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>326</td>\n",
       "      <td>3.36</td>\n",
       "      <td>8911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crime</td>\n",
       "      <td>139</td>\n",
       "      <td>3.54</td>\n",
       "      <td>4671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>13</td>\n",
       "      <td>3.81</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>342</td>\n",
       "      <td>3.61</td>\n",
       "      <td>10201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>124</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horror</td>\n",
       "      <td>56</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>68</td>\n",
       "      <td>3.59</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Romance</td>\n",
       "      <td>151</td>\n",
       "      <td>3.39</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>174</td>\n",
       "      <td>3.42</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>245</td>\n",
       "      <td>3.44</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          genre  num movies  ave rating/genre  ratings per genre\n",
       "0        Action         321              3.37              10377\n",
       "1     Adventure         234              3.42               8785\n",
       "2     Animation          76              3.63               2588\n",
       "3      Children          69              3.44               2472\n",
       "4        Comedy         326              3.36               8911\n",
       "5         Crime         139              3.54               4671\n",
       "6   Documentary          13              3.81                280\n",
       "7         Drama         342              3.61              10201\n",
       "8       Fantasy         124              3.37               4468\n",
       "9        Horror          56              3.20               1345\n",
       "10      Mystery          68              3.59               2497\n",
       "11      Romance         151              3.39               4468\n",
       "12       Sci-Fi         174              3.42               5894\n",
       "13     Thriller         245              3.44               7659"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10Df = pd.read_csv(\"./data/content_top10_df.csv\")\n",
    "byGenreDf = pd.read_csv(\"./data/content_bygenre_df.csv\")\n",
    "byGenreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ''' called to load preprepared data for the lab '''\n",
    "    item_train = genfromtxt('./data/content_item_train.csv', delimiter=',')\n",
    "    user_train = genfromtxt('./data/content_user_train.csv', delimiter=',')\n",
    "    y_train    = genfromtxt('./data/content_y_train.csv', delimiter=',')\n",
    "    with open('./data/content_item_train_header.txt', newline='') as f:    #csv reader handles quoted strings better\n",
    "        item_features = list(csv.reader(f))[0]\n",
    "    with open('./data/content_user_train_header.txt', newline='') as f:\n",
    "        user_features = list(csv.reader(f))[0]\n",
    "    item_vecs = genfromtxt('./data/content_item_vecs.csv', delimiter=',')\n",
    "\n",
    "    movie_dict = defaultdict(dict)\n",
    "    count = 0\n",
    "#    with open('./data/movies.csv', newline='') as csvfile:\n",
    "    with open('./data/content_movie_list.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for line in reader:\n",
    "            if count == 0:\n",
    "                count += 1  #skip header\n",
    "                #print(line) print\n",
    "            else:\n",
    "                count += 1\n",
    "                movie_id = int(line[0])\n",
    "                movie_dict[movie_id][\"title\"] = line[1]\n",
    "                movie_dict[movie_id][\"genres\"] = line[2]\n",
    "\n",
    "    with open('./data/content_user_to_genre.pickle', 'rb') as f:\n",
    "        user_to_genre = pickle.load(f)\n",
    "\n",
    "    return(item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data, set configuration variables\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Scaling the trained data\n",
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = user_train\n",
    "target_train_unscaled =  y_train\n",
    "\n",
    "# The input data are scaled with standard normalization\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(item_train)\n",
    "item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(user_train)\n",
    "user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1,1))\n",
    "scalerTarget.fit(y_train.reshape((-1,1)))\n",
    "y_train = scalerTarget.transform(y_train.reshape((-1,1)))\n",
    "\n",
    "print(np.allclose(item_train_unscaled, scalerItem.inverse_transform(item_train)))\n",
    "print(np.allclose(user_train_unscaled, scalerUser.inverse_transform(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie/item training data shape: (40707, 17)\n",
      "movie/item test data shape: (10177, 17)\n"
     ]
    }
   ],
   "source": [
    "itemTrain, itemTest = train_test_split(item_train, train_size=.8, shuffle=True, random_state=1)\n",
    "userTrain, userTest = train_test_split(user_train, train_size=.8, shuffle=True, random_state=1)\n",
    "yTrain, yTest        =   train_test_split(y_train, train_size=.8, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {itemTrain.shape}\")\n",
    "print(f\"movie/item test data shape: {itemTest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)     (None, 32)           40864       ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)     (None, 32)           41376       ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_8 (TFOpLa  (None, 32)          0           ['sequential_16[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_9 (TFOpLa  (None, 32)          0           ['sequential_17[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_8[0][0]', \n",
      "                                                                  'tf.math.l2_normalize_9[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,240\n",
      "Trainable params: 82,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "numOutputs = 32\n",
    "tf.random.set_seed(1)\n",
    "userNN = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=numOutputs, activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "itemNN = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=numOutputs, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the user input Neural network\n",
    "inputUser = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = userNN(inputUser)\n",
    "vu = tf.linalg.l2_normalize(vu, axis = 1)\n",
    "\n",
    "# Create the item input Neural network\n",
    "inputItem = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = itemNN(inputItem)\n",
    "vm = tf.linalg.l2_normalize(vm, axis = 1)\n",
    "\n",
    "# Add the dot product and output\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "model = tf.keras.Model([inputUser, inputItem], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1273/1273 [==============================] - 3s 2ms/step - loss: 0.1238\n",
      "Epoch 2/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.1150\n",
      "Epoch 3/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1108\n",
      "Epoch 4/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1063\n",
      "Epoch 5/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1038\n",
      "Epoch 6/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1007\n",
      "Epoch 7/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0985\n",
      "Epoch 8/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0962\n",
      "Epoch 9/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0940\n",
      "Epoch 10/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0924\n",
      "Epoch 11/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0906\n",
      "Epoch 12/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0888\n",
      "Epoch 13/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0877\n",
      "Epoch 14/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0865\n",
      "Epoch 15/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0852\n",
      "Epoch 16/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0838\n",
      "Epoch 17/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0827\n",
      "Epoch 18/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0816\n",
      "Epoch 19/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0807\n",
      "Epoch 20/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0796\n",
      "Epoch 21/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0787\n",
      "Epoch 22/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0780\n",
      "Epoch 23/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0771\n",
      "Epoch 24/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0763\n",
      "Epoch 25/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0754\n",
      "Epoch 26/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0748\n",
      "Epoch 27/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0740\n",
      "Epoch 28/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0735\n",
      "Epoch 29/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0729\n",
      "Epoch 30/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20938d3e880>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=.01)\n",
    ")\n",
    "model.fit([userTrain[:, u_s:], itemTrain[:, i_s:]], yTrain, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 0s 1ms/step - loss: 0.0817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08165575563907623"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([userTest[:, u_s:], itemTest[:, i_s:]], yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "def gen_user_vecs(user_vec, num_items):\n",
    "    \"\"\" given a user vector return:\n",
    "        user predict maxtrix to match the size of item_vecs \"\"\"\n",
    "    user_vecs = np.tile(user_vec, (num_items, 1))\n",
    "    return user_vecs\n",
    "def get_user_vecs(user_id, user_train, item_vecs, user_to_genre):\n",
    "    \"\"\" given a user_id, return:\n",
    "        user train/predict matrix to match the size of item_vecs\n",
    "        y vector with ratings for all rated movies and 0 for others of size item_vecs \"\"\"\n",
    "\n",
    "    if not user_id in user_to_genre:\n",
    "        print(\"error: unknown user id\")\n",
    "        return None\n",
    "    else:\n",
    "        user_vec_found = False\n",
    "        for i in range(len(user_train)):\n",
    "            if user_train[i, 0] == user_id:\n",
    "                user_vec = user_train[i]\n",
    "                user_vec_found = True\n",
    "                break\n",
    "        if not user_vec_found:\n",
    "            print(\"error in get_user_vecs, did not find uid in user_train\")\n",
    "        num_items = len(item_vecs)\n",
    "        user_vecs = np.tile(user_vec, (num_items, 1))\n",
    "\n",
    "        y = np.zeros(num_items)\n",
    "        for i in range(num_items):  # walk through movies in item_vecs and get the movies, see if user has rated them\n",
    "            movie_id = item_vecs[i, 0]\n",
    "            if movie_id in user_to_genre[user_id]['movies']:\n",
    "                rating = user_to_genre[user_id]['movies'][movie_id]\n",
    "            else:\n",
    "                rating = 0\n",
    "            y[i] = rating\n",
    "    return(user_vecs, y)\n",
    "# Prediction for a new user\n",
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])\n",
    "\n",
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "uid = 2 \n",
    "# form a set of user vectors. This is the same vector, transformed and repeated.\n",
    "user_vecs, y_vecs = get_user_vecs(uid, user_train_unscaled, item_vecs, user_to_genre)\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "sorted_user  = user_vecs[sorted_index]\n",
    "sorted_y     = y_vecs[sorted_index]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".MotherVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
